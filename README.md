# Face Emotion Recognition

The Face Emotion Recognition project is developed using the Mediapipe framework. It allows for the detection and recognition of emotions from a person's face. The project utilizes the Mediapipe holistic model for face analysis and employs a random forest classifier for emotion predictions.

## Features

- **Face Emotion Detection**: The system can detect and recognize emotions from facial expressions captured through a camera or input image.

- **Mediapipe Holistic Model**: The project utilizes the Mediapipe holistic model, which combines face, hand, and pose recognition, to accurately analyze and extract facial features for emotion recognition.

- **Random Forest Classifier**: Emotion predictions are made using a random forest classifier, trained on labeled data, which has been preprocessed and transformed from the extracted facial features.

## Installation

To set up the Face Emotion Recognition project locally, follow these steps:

1. Clone the repository:

   ```shell
   git clone https://github.com/your-username/face-emotion-recognition.git

## Dataset
The face emotion recognition model has been trained on a labeled dataset containing facial expressions and corresponding emotions. The dataset used for training the random forest classifier.The Dataset is prepared by using my own facial expressions
## Usage
Launch the project and ensure your camera is connected or provide an image for emotion recognition.

The system will detect faces in the image or video feed and overlay the predicted emotion on each detected face.

You can view the recognized emotions in real-time or from the processed image.

Experiment with different facial expressions and observe how the system recognizes and classifies emotions.
